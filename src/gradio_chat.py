# -*- coding: utf-8 -*-
"""
@author:XuMing(xuming624@qq.com)
@description:

A simplified Gradio demo for Deep Research with basic conversation interface.
"""

import time
import gradio as gr
from loguru import logger
from .config import get_config
from .deep_research import (
    deep_research_stream,
    generate_followup_questions,
    process_clarifications,
    write_final_report,
    should_clarify_query
)

# Load configuration
config = get_config()


def run_gradio_demo():
    """Run a modern Gradio demo for Deep Research using ChatInterface"""
    enable_clarification = config.get("research", {}).get("enable_clarification", False)
    search_source = config.get("research", {}).get("search_source", "tavily")

    # Conversation state (shared across functions)
    conversation_state = {
        "current_query": "",
        "needs_clarification": False,
        "questions": [],
        "waiting_for_clarification": False,
        "clarification_answers": {},
        "last_status": "",  # è·Ÿè¸ªæœ€åä¸€ä¸ªçŠ¶æ€æ›´æ–°
        "history": [],  # ä¿å­˜å½“å‰èŠå¤©å†å²
        "search_source": search_source,  # å­˜å‚¨æœç´¢æä¾›å•†
        "enable_clarification": enable_clarification  # å­˜å‚¨æ˜¯å¦å¯ç”¨æ¾„æ¸…
    }

    async def research_with_thinking(message, history):
        """å¤„ç†æŸ¥è¯¢ï¼Œå±•ç¤ºç ”ç©¶è¿‡ç¨‹å¹¶è¿”å›ç»“æœ"""
        if not message:
            yield history  # ç©ºæ¶ˆæ¯ï¼Œç›´æ¥è¿”å›
            return  # æ— å€¼è¿”å›æ˜¯å…è®¸çš„

        # é‡ç½®çŠ¶æ€ï¼Œç¡®ä¿å¤šæ¬¡æŸ¥è¯¢ä¹‹é—´çŠ¶æ€ä¸æ··æ·†
        conversation_state["last_status"] = ""
        conversation_state["current_query"] = ""
        conversation_state["questions"] = []

        # åˆ¤æ–­æ˜¯å¦æ˜¯æ¾„æ¸…å›ç­”ï¼Œå¦‚æœæ˜¯åˆ™ä¸é‡ç½®waiting_for_clarification
        if not conversation_state["waiting_for_clarification"]:
            conversation_state["waiting_for_clarification"] = False
            conversation_state["clarification_answers"] = {}

        logger.debug(
            f"Starting research, message: {message}, search_source: {search_source}, enable_clarification: {enable_clarification}")

        # æ„å»ºå†å²ä¸Šä¸‹æ–‡ - ç›´æ¥ä½¿ç”¨historyå³å¯
        history_context = ''
        for msg in history:
            if isinstance(msg, dict) and msg.get("role") == "user":
                q = 'Q:' + msg.get("content", "") + '\n'
                history_context += q

        # 3. æ£€æŸ¥æ˜¯å¦æ˜¯å¯¹æ¾„æ¸…é—®é¢˜çš„å›ç­”
        if conversation_state["waiting_for_clarification"]:
            async for msg in handle_clarification_answer(message, history, history_context):
                yield msg
            return  # æ— å€¼è¿”å›æ˜¯å…è®¸çš„

        # 4. åˆ›å»ºç ”ç©¶è¿‡ç¨‹æ¶ˆæ¯å¹¶å°†å…¶æ·»åŠ åˆ°å†å²è®°å½•
        messages = []
        messages.append({"role": "assistant", "content": "æ­£åœ¨è¿›è¡Œç ”ç©¶...", "metadata": {"title": "ç ”ç©¶è¿‡ç¨‹"}})
        yield messages

        # 5. å¤„ç†æ¾„æ¸…ç¯èŠ‚
        if not enable_clarification:
            messages[-1]["content"] = "è·³è¿‡æ¾„æ¸…ç¯èŠ‚ï¼Œç›´æ¥å¼€å§‹ç ”ç©¶..."
            yield messages
        else:
            # åˆ†ææŸ¥è¯¢æ˜¯å¦éœ€è¦æ¾„æ¸…
            messages[-1]["content"] = "åˆ†ææŸ¥è¯¢éœ€æ±‚ä¸­..."
            yield messages

            needs_clarification = await should_clarify_query(message, history_context)
            if needs_clarification:
                messages[-1]["content"] = "ç”Ÿæˆæ¾„æ¸…é—®é¢˜..."
                yield messages

                followup_result = await generate_followup_questions(message, history_context)
                questions = followup_result.get("questions", [])

                if questions:
                    # ä¿å­˜é—®é¢˜å’ŒçŠ¶æ€
                    conversation_state["current_query"] = message
                    conversation_state["questions"] = questions
                    conversation_state["waiting_for_clarification"] = True

                    # æ˜¾ç¤ºé—®é¢˜ç»™ç”¨æˆ·
                    clarification_msg = "è¯·å›ç­”ä»¥ä¸‹é—®é¢˜ï¼Œå¸®åŠ©æˆ‘æ›´å¥½åœ°ç†è§£æ‚¨çš„æŸ¥è¯¢:"
                    for i, q in enumerate(questions, 1):
                        clarification_msg += f"\n{i}. {q.get('question', '')}"

                    # æ›¿æ¢ç ”ç©¶è¿‡ç¨‹æ¶ˆæ¯ä¸ºæ¾„æ¸…é—®é¢˜
                    messages[-1] = {"role": "assistant", "content": clarification_msg}
                    yield messages
                    return  # ç­‰å¾…ç”¨æˆ·å›ç­”
                else:
                    messages[-1]["content"] = "æ— æ³•ç”Ÿæˆæœ‰æ•ˆçš„æ¾„æ¸…é—®é¢˜ï¼Œç»§ç»­ç ”ç©¶..."
                    yield messages
            else:
                messages[-1]["content"] = "æŸ¥è¯¢å·²è¶³å¤Ÿæ¸…æ™°ï¼Œå¼€å§‹ç ”ç©¶..."
                yield messages

        # 6. å¼€å§‹æœç´¢
        messages[-1]["content"] = f"ä½¿ç”¨ {search_source} æœç´¢ç›¸å…³ä¿¡æ¯ä¸­..."
        yield messages

        # 7. æ‰§è¡Œç ”ç©¶è¿‡ç¨‹
        final_result = None
        research_log = []

        async for partial_result in deep_research_stream(
                query=message,
                search_source=search_source,
                history_context=history_context,
                enable_clarification=enable_clarification
        ):
            # æ›´æ–°ç ”ç©¶è¿›åº¦
            if partial_result.get("status_update"):
                status = partial_result.get("status_update")
                stage = partial_result.get("stage", "")

                # æ£€æŸ¥çŠ¶æ€æ˜¯å¦æœ‰å˜åŒ–
                if status != conversation_state["last_status"]:
                    conversation_state["last_status"] = status

                    # æ›´æ–°ç ”ç©¶è¿›åº¦æ¶ˆæ¯
                    timestamp = time.strftime('%H:%M:%S')
                    status_line = f"[{timestamp}] {status}"
                    research_log.append(status_line)

                    # æ˜¾ç¤ºå½“å‰ç ”ç©¶è®¡åˆ’æ­¥éª¤
                    if partial_result.get("current_step"):
                        current_step = partial_result.get("current_step")
                        step_id = current_step.get("step_id", "")
                        description = current_step.get("description", "")
                        step_line = f"å½“å‰æ­¥éª¤ {step_id}: {description}"
                        research_log.append(step_line)

                    # æ˜¾ç¤ºå½“å‰æŸ¥è¯¢
                    if partial_result.get("current_queries"):
                        queries = partial_result.get("current_queries")
                        queries_lines = ["**å½“å‰å¹¶è¡ŒæŸ¥è¯¢**:"]
                        for i, q in enumerate(queries, 1):
                            queries_lines.append(f"{i}. {q}")
                        research_log.append("\n".join(queries_lines))

                    # å¯¹äºç‰¹å®šé˜¶æ®µï¼Œæ·»åŠ æ›´å¤šä¿¡æ¯
                    if stage == "plan_generated" and partial_result.get("research_plan"):
                        research_plan = partial_result.get("research_plan")
                        plan_lines = ["**ç ”ç©¶è®¡åˆ’**:"]
                        for i, step in enumerate(research_plan):
                            step_id = step.get("step_id", i + 1)
                            description = step.get("description", "")
                            plan_lines.append(f"æ­¥éª¤ {step_id}: {description}")
                        research_log.append("\n".join(plan_lines))

                    # æ·»åŠ é˜¶æ®µè¯¦ç»†ä¿¡æ¯
                    if stage == "insights_found" and partial_result.get("formatted_new_learnings"):
                        if partial_result.get("formatted_new_urls") and len(
                                partial_result.get("formatted_new_urls")) > 0:
                            research_log.append("\n**æ¥æº**:\n" + "\n".join(
                                partial_result.get("formatted_new_urls", [])[:3]))

                    elif stage == "step_completed" and partial_result.get("formatted_step_learnings"):
                        research_log.append("\n**æ­¥éª¤æ€»ç»“**:\n" + "\n".join(
                            partial_result.get("formatted_step_learnings", [])))

                    elif stage == "analysis_completed" and partial_result.get("formatted_final_findings"):
                        research_log.append("\n**ä¸»è¦å‘ç°**:\n" + "\n".join(
                            partial_result.get("formatted_final_findings", [])))

                        if partial_result.get("gaps"):
                            research_log.append("\n\n**ç ”ç©¶ç©ºç™½**:\n- " + "\n- ".join(partial_result.get("gaps", [])))

                    # åˆå¹¶æ‰€æœ‰æ—¥å¿—å¹¶æ›´æ–°ç ”ç©¶è¿‡ç¨‹æ¶ˆæ¯
                    messages[-1]["content"] = "\n\n".join(research_log)
                    yield messages

            # ä¿å­˜æœ€åä¸€ä¸ªç»“æœç”¨äºç”ŸæˆæŠ¥å‘Š
            final_result = partial_result

            # å¦‚æœæœ‰æœ€ç»ˆæŠ¥å‘Šï¼Œè·³å‡ºå¾ªç¯
            if "final_report" in partial_result:
                break

        # 8. ç”ŸæˆæŠ¥å‘Š
        if final_result:
            # å¦‚æœç›´æ¥åœ¨ç»“æœä¸­æœ‰final_reportï¼Œç›´æ¥ä½¿ç”¨
            if "final_report" in final_result:
                report = final_result["final_report"]
                # æ ‡è®°ç ”ç©¶è¿‡ç¨‹æ¶ˆæ¯å·²å®Œæˆ
                research_process = messages[-1]["content"]
                messages[-1]["content"] = "ç ”ç©¶å®Œæˆï¼ŒæŠ¥å‘Šå·²ç”Ÿæˆã€‚\n\n" + research_process
                yield messages
            else:
                # å¦åˆ™ï¼Œä½¿ç”¨æ”¶é›†åˆ°çš„ä¿¡æ¯ç”ŸæˆæŠ¥å‘Š
                research_process = messages[-1]["content"]
                messages[-1]["content"] = "æ­£åœ¨æ•´åˆç ”ç©¶ç»“æœå¹¶ç”ŸæˆæŠ¥å‘Š...\n\n" + research_process
                yield messages

                learnings = final_result.get("learnings", [])

                try:
                    report = await write_final_report(
                        query=message,
                        context=str(learnings),
                        history_context=history_context
                    )
                    # ç¡®ä¿reportä¸ä¸ºNone
                    if report is None:
                        report = "æŠ±æ­‰ï¼Œæ— æ³•ç”Ÿæˆç ”ç©¶æŠ¥å‘Šã€‚"
                        logger.error(f"write_final_report returned None for query: {message}")
                except Exception as e:
                    report = f"ç”ŸæˆæŠ¥å‘Šæ—¶å‡ºé”™: {str(e)}"
                    logger.error(f"Error in write_final_report: {str(e)}")

                # ä¿ç•™ç ”ç©¶è¿‡ç¨‹ä¿¡æ¯
                messages[-1]["content"] = "ç ”ç©¶å®Œæˆï¼ŒæŠ¥å‘Šå·²ç”Ÿæˆã€‚\n\n" + research_process
                yield messages

            # æ·»åŠ æœ€ç»ˆæŠ¥å‘Šæ¶ˆæ¯ï¼Œä½†ä¿ç•™ç ”ç©¶è¿‡ç¨‹æ¶ˆæ¯
            messages.append({"role": "assistant", "content": report})
            yield messages
        else:
            messages.append(
                {"role": "assistant", "content": "æŠ±æ­‰ï¼Œæˆ‘æ— æ³•ä¸ºæ‚¨çš„æŸ¥è¯¢ç”Ÿæˆç ”ç©¶æŠ¥å‘Šã€‚è¯·å°è¯•å…¶ä»–é—®é¢˜æˆ–ç¨åå†è¯•ã€‚"})
            yield messages

    async def handle_clarification_answer(message, history, history_context):
        """å¤„ç†ç”¨æˆ·å¯¹æ¾„æ¸…é—®é¢˜çš„å›ç­”"""
        # é‡ç½®ç­‰å¾…æ ‡å¿—
        conversation_state["waiting_for_clarification"] = False

        # è·å–åŸå§‹æŸ¥è¯¢å’Œé—®é¢˜
        query = conversation_state["current_query"]
        questions = conversation_state["questions"]

        # é‡ç½®çŠ¶æ€ï¼Œç¡®ä¿å¤šæ¬¡æŸ¥è¯¢ä¹‹é—´çŠ¶æ€ä¸æ··æ·†
        conversation_state["last_status"] = ""

        # 1. åˆ›å»ºæ¶ˆæ¯åˆ—è¡¨å¹¶æ·»åŠ ç ”ç©¶è¿‡ç¨‹æ¶ˆæ¯
        messages = []
        messages.append({"role": "assistant", "content": "è§£ææ‚¨çš„æ¾„æ¸…å›ç­”...", "metadata": {"title": "ç ”ç©¶è¿‡ç¨‹"}})
        yield messages

        # 2. è§£æç”¨æˆ·å›ç­”
        lines = [line.strip() for line in message.split('\n') if line.strip()]
        if len(lines) < len(questions):
            # å°è¯•é€—å·åˆ†éš”
            if ',' in message:
                lines = [ans.strip() for ans in message.split(',')]

        # 3. åˆ›å»ºå“åº”å­—å…¸
        user_responses = {}
        for i, q in enumerate(questions):
            key = q.get("key", f"q{i}")
            if i < len(lines) and lines[i]:
                user_responses[key] = lines[i]

        # 4. å¤„ç†æ¾„æ¸…å†…å®¹
        messages[-1]["content"] = "å¤„ç†æ‚¨çš„æ¾„æ¸…å†…å®¹..."
        yield messages

        # 5. å¤„ç†æ¾„æ¸…å¹¶ä¼˜åŒ–æŸ¥è¯¢
        clarification_result = await process_clarifications(
            query=query,
            user_responses=user_responses,
            all_questions=questions,
            history_context=history_context
        )

        # 6. è·å–ä¼˜åŒ–åçš„æŸ¥è¯¢
        refined_query = clarification_result.get("refined_query", query)
        messages[-1]["content"] = f"å·²ä¼˜åŒ–æŸ¥è¯¢: {refined_query}"
        yield messages

        # 7. æ£€æŸ¥æ˜¯å¦å¯ä»¥ç›´æ¥å›ç­”
        if not clarification_result.get("requires_search", True) and clarification_result.get("direct_answer"):
            direct_answer = clarification_result.get("direct_answer", "")

            # ä¿ç•™ç ”ç©¶è¿‡ç¨‹æ¶ˆæ¯ï¼Œå¹¶æ·»åŠ ç›´æ¥å›ç­”
            research_process = messages[-1]["content"]
            messages[-1]["content"] = "æä¾›ç›´æ¥å›ç­”ï¼Œæ— éœ€æœç´¢ã€‚\n\n" + research_process
            yield messages

            # æ·»åŠ æœ€ç»ˆå›ç­”ï¼Œä½†ä¿ç•™ç ”ç©¶è¿‡ç¨‹
            messages.append({"role": "assistant", "content": direct_answer})
            yield messages

        # 8. å¼€å§‹æœç´¢
        messages[-1]["content"] = "åŸºäºæ‚¨çš„æ¾„æ¸…å¼€å§‹æœç´¢ä¿¡æ¯..."
        yield messages

        # 9. æ‰§è¡Œç ”ç©¶è¿‡ç¨‹
        final_result = None
        research_log = []

        async for partial_result in deep_research_stream(
                query=refined_query,
                user_clarifications=user_responses,
                search_source=search_source,
                history_context=history_context
        ):
            # æ›´æ–°ç ”ç©¶è¿›åº¦
            if partial_result.get("status_update"):
                status = partial_result.get("status_update")
                stage = partial_result.get("stage", "")

                # æ£€æŸ¥çŠ¶æ€æ˜¯å¦æœ‰å˜åŒ–
                if status != conversation_state["last_status"]:
                    conversation_state["last_status"] = status

                    # æ›´æ–°ç ”ç©¶è¿›åº¦æ¶ˆæ¯
                    timestamp = time.strftime('%H:%M:%S')
                    status_line = f"[{timestamp}] {status}"
                    research_log.append(status_line)

                    # æ˜¾ç¤ºå½“å‰ç ”ç©¶è®¡åˆ’æ­¥éª¤
                    if partial_result.get("current_step"):
                        current_step = partial_result.get("current_step")
                        step_id = current_step.get("step_id", "")
                        description = current_step.get("description", "")
                        step_line = f"å½“å‰æ­¥éª¤ {step_id}: {description}"
                        research_log.append(step_line)

                    # æ˜¾ç¤ºå½“å‰æŸ¥è¯¢
                    if partial_result.get("current_queries"):
                        queries = partial_result.get("current_queries")
                        queries_lines = ["å½“å‰å¹¶è¡ŒæŸ¥è¯¢:"]
                        for i, q in enumerate(queries, 1):
                            queries_lines.append(f"{i}. {q}")
                        research_log.append("\n".join(queries_lines))

                    # å¯¹äºç‰¹å®šé˜¶æ®µï¼Œæ·»åŠ æ›´å¤šä¿¡æ¯
                    if stage == "plan_generated" and partial_result.get("research_plan"):
                        research_plan = partial_result.get("research_plan")
                        plan_lines = ["ç ”ç©¶è®¡åˆ’:"]
                        for i, step in enumerate(research_plan):
                            step_id = step.get("step_id", i + 1)
                            description = step.get("description", "")
                            plan_lines.append(f"æ­¥éª¤ {step_id}: {description}")
                        research_log.append("\n".join(plan_lines))

                    # æ·»åŠ é˜¶æ®µè¯¦ç»†ä¿¡æ¯
                    if stage == "insights_found" and partial_result.get("formatted_new_learnings"):
                        if partial_result.get("formatted_new_urls") and len(
                                partial_result.get("formatted_new_urls")) > 0:
                            research_log.append("\n**æ¥æº**:\n" + "\n".join(
                                partial_result.get("formatted_new_urls", [])[:3]))

                    elif stage == "step_completed" and partial_result.get("formatted_step_learnings"):
                        research_log.append("\n**æ­¥éª¤æ€»ç»“**:\n" + "\n".join(
                            partial_result.get("formatted_step_learnings", [])))

                    elif stage == "analysis_completed" and partial_result.get("formatted_final_findings"):
                        research_log.append("\n**ä¸»è¦å‘ç°**:\n" + "\n".join(
                            partial_result.get("formatted_final_findings", [])))

                        if partial_result.get("gaps"):
                            research_log.append("\n\n**ç ”ç©¶ç©ºç™½**:\n- " + "\n- ".join(partial_result.get("gaps", [])))

                    # åˆå¹¶æ‰€æœ‰æ—¥å¿—å¹¶æ›´æ–°ç ”ç©¶è¿‡ç¨‹æ¶ˆæ¯
                    messages[-1]["content"] = "\n\n".join(research_log)
                    yield messages

            # ä¿å­˜æœ€åä¸€ä¸ªç»“æœç”¨äºç”ŸæˆæŠ¥å‘Š
            final_result = partial_result

            # å¦‚æœæœ‰æœ€ç»ˆæŠ¥å‘Šï¼Œè·³å‡ºå¾ªç¯
            if "final_report" in partial_result:
                break

        # 10. ç”ŸæˆæŠ¥å‘Š
        if final_result:
            # å¦‚æœç›´æ¥åœ¨ç»“æœä¸­æœ‰final_reportï¼Œç›´æ¥ä½¿ç”¨
            if "final_report" in final_result:
                report = final_result["final_report"]
                # æ ‡è®°ç ”ç©¶è¿‡ç¨‹æ¶ˆæ¯å·²å®Œæˆ
                research_process = messages[-1]["content"]
                messages[-1]["content"] = "ç ”ç©¶å®Œæˆï¼ŒæŠ¥å‘Šå·²ç”Ÿæˆã€‚\n\n" + research_process
                yield messages
            else:
                # å¦åˆ™ï¼Œä½¿ç”¨æ”¶é›†åˆ°çš„ä¿¡æ¯ç”ŸæˆæŠ¥å‘Š
                research_process = messages[-1]["content"]
                messages[-1]["content"] = "æ­£åœ¨æ•´åˆç ”ç©¶ç»“æœå¹¶ç”ŸæˆæŠ¥å‘Š...\n\n" + research_process
                yield messages

                learnings = final_result.get("learnings", [])

                try:
                    report = await write_final_report(
                        query=refined_query,
                        context=str(learnings),
                        history_context=history_context
                    )
                    # ç¡®ä¿reportä¸ä¸ºNone
                    if report is None:
                        report = "æŠ±æ­‰ï¼Œæ— æ³•ç”Ÿæˆç ”ç©¶æŠ¥å‘Šã€‚"
                        logger.error(f"returned None for query: {refined_query}")
                except Exception as e:
                    report = f"ç”ŸæˆæŠ¥å‘Šæ—¶å‡ºé”™: {str(e)}"
                    logger.error(f"Error in write_final_report: {str(e)}")

                # ä¿ç•™ç ”ç©¶è¿‡ç¨‹ä¿¡æ¯
                messages[-1]["content"] = "ç ”ç©¶å®Œæˆï¼ŒæŠ¥å‘Šå·²ç”Ÿæˆã€‚\n\n" + research_process
                yield messages

            # æ·»åŠ æœ€ç»ˆæŠ¥å‘Šæ¶ˆæ¯ï¼Œä½†ä¿ç•™ç ”ç©¶è¿‡ç¨‹æ¶ˆæ¯
            messages.append({"role": "assistant", "content": report})
            yield messages
        else:
            messages.append(
                {"role": "assistant", "content": "æŠ±æ­‰ï¼Œæˆ‘æ— æ³•ä¸ºæ‚¨çš„æŸ¥è¯¢ç”Ÿæˆç ”ç©¶æŠ¥å‘Šã€‚è¯·å°è¯•å…¶ä»–é—®é¢˜æˆ–ç¨åå†è¯•ã€‚"})
            yield messages

    # åˆ›å»º ChatInterface
    demo = gr.ChatInterface(
        research_with_thinking,
        type='messages',
        title="ğŸ” Deep Research",
        description="ä½¿ç”¨æ­¤å·¥å…·è¿›è¡Œæ·±åº¦ç ”ç©¶ï¼Œæˆ‘å°†æœç´¢äº’è”ç½‘ä¸ºæ‚¨æ‰¾åˆ°å›ç­”ã€‚Powered by [Deep Research](https://github.com/shibing624/deep-research) Made with â¤ï¸ by [shibing624](https://github.com/shibing624)",
        examples=[
            ["ç‰¹æ–¯æ‹‰è‚¡ç¥¨çš„æœ€æ–°è¡Œæƒ…?"],
            ["ä»‹ç»ä¸€ä¸‹æœ€è¿‘çš„äººå·¥æ™ºèƒ½æŠ€æœ¯å‘å±•è¶‹åŠ¿"],
            ["ä¸­å›½2024å¹´GDPå¢é•¿äº†å¤šå°‘?"],
            ["Explain the differences between supervised and unsupervised machine learning."]
        ]
    )

    # å¯åŠ¨ç•Œé¢
    demo.queue()
    demo.launch(server_name="0.0.0.0", share=False, server_port=7860, show_api=False)


if __name__ == "__main__":
    run_gradio_demo()
